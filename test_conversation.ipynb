{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Conversation\n",
    "\n",
    "Simple notebook to test conversations:\n",
    "1. Paste exported conversation\n",
    "2. Set model\n",
    "3. Run cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-time setup\n",
    "!pip install requests python-dotenv -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport json\nimport requests\nfrom dotenv import load_dotenv\n\nload_dotenv()\nAPI_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n\n# ============================================================\n# PASTE EXPORTED CONVERSATION HERE\n# ============================================================\nconversation = {\n  \"messages\": [\n    {\"role\": \"system\", \"content\": \"System prompt here\"},\n    {\"role\": \"user\", \"content\": \"User message here\"}\n  ]\n}\n\n# ============================================================\n# SET MODEL HERE\n# ============================================================\nmodel = \"anthropic/claude-sonnet-4.5\"\n# Options:\n#   \"anthropic/claude-sonnet-4.5\" (pro tier storytelling, best reasoning)\n#   \"anthropic/claude-haiku-4.5\" (free tier storytelling, fast)\n#   \"google/gemini-2.5-pro\" (pro tier management)\n#   \"google/gemini-2.5-flash\" (free tier management, fast)\n\n# ============================================================\n# RUN (automatic with high reasoning effort)\n# ============================================================\nprint(f\"üöÄ Testing {model} with {len(conversation['messages'])} messages...\\n\")\n\npayload = {\n    \"model\": model,\n    \"input\": [\n        {\"type\": \"message\", \"role\": msg[\"role\"], \"content\": [{\"type\": \"input_text\", \"text\": msg[\"content\"]}]}\n        for msg in conversation[\"messages\"]\n    ],\n    \"reasoning\": {\"effort\": \"high\"},\n    \"max_output_tokens\": 8000,\n    \"stream\": False,\n}\n\nresponse = requests.post(\n    \"https://openrouter.ai/api/v1/responses\",\n    headers={\"Authorization\": f\"Bearer {API_KEY}\", \"Content-Type\": \"application/json\"},\n    json=payload,\n)\n\nresult = response.json()\n\n# Show reasoning\nfor item in result.get('output', []):\n    if item.get('type') == 'reasoning':\n        print(\"üß† REASONING:\")\n        for i, step in enumerate(item.get('summary', []), 1):\n            print(f\"  {i}. {step}\")\n        print()\n\n# Show response\nfor item in result.get('output', []):\n    if item.get('type') == 'message':\n        for content in item.get('content', []):\n            if content.get('type') == 'output_text':\n                print(\"üìù RESPONSE:\\n\")\n                print(content.get('text', ''))\n                print(\"\\n\" + \"=\"*80)\n\n# Show usage\nif 'usage' in result:\n    usage = result['usage']\n    total = usage.get('total_tokens', 0)\n    reasoning = usage.get('output_tokens_details', {}).get('reasoning_tokens', 0)\n    print(f\"\\nüìä Tokens: {total} total ({reasoning} reasoning)\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecaster",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}